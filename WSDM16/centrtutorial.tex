\PassOptionsToPackage{pdfpagelabels=false}{hyperref} % To shut down hyperref warnings
\documentclass{sig-alternate}
\setlength{\paperheight}{11in} % To shut down hyperref warnings
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage[numbers,square,sort&compress]{natbib}
\renewcommand{\refname}{References}
\renewcommand{\bibsection}{\subsection*{References}}
\renewcommand*{\bibfont}{\raggedright}
\usepackage{mdwlist}

\renewcommand{\labelenumi}{\arabic{enumi}.}
\renewcommand{\labelenumii}{\arabic{enumi}.\arabic{enumii}}

\newcommand{\spara}[1]{\smallskip\noindent{\bf #1}}
\newcommand{\para}[1]{\noindent{\bf #1}}

\makeatletter
\def\@copyrightspace{\relax}
\makeatother

\begin{document}

\numberofauthors{3}

\title{Centrality Measures on Big Graphs:\\Exact, Approximated, and Distributed Algorithms}
\subtitle{Proposal for a Half-day Tutorial at ACM WSDM'16}

\author{
\alignauthor
Francesco Bonchi\\
       \affaddr{ISI Foundation}\\
       \affaddr{Turin, Italy}\\
       \email{francescobonchi@acm.org}
\end{tabular}\begin{tabular}[t]{p{1.3\auwidth}}\centering
Gianmarco~De~Francisci~Morales\\
       \affaddr{Aalto University}\\
       \affaddr{Helsinki, Finland}\\
       \email{gdfm@acm.org}
\alignauthor
Matteo Riondato\titlenote{Main contact person}\\
       \affaddr{Two Sigma Investments}\\
       \affaddr{New York, NY, USA}\\
       \email{matteo@twosigma.com}
}
\date{\today}

\maketitle

\begin{abstract}
	\emph{Centrality measures} allow to measure the relative \emph{importance}
	of a node or an edge in a graph. %w.r.t.~other nodes or edges.
	Several measures of centrality are available in the literature, each capturing different
	aspects of the informal concept of importance, paired with
	several algorithms to compute them.

	In this tutorial, we survey the different definitions of centrality measures
	and the algorithms to compute them. We start from the most common measures
	(e.g., closeness, betweenness) and move to more
	complex ones, such as spanning-edge centrality. In our presentation of the
	algorithms, we begin from exact ones, and progress to
	approximation algorithms, including sampling-based ones, and to
	scalable MapReduce algorithms for huge graphs, both for exact
	computation and for keeping the measures up-to-date on dynamic graphs,
	where edges change over time.
	% where edges are inserted or deleted over time.

	Our goal is to show how advanced algorithmic techniques and scalable systems
	can be used to obtain efficient algorithms for an important graph mining
	tasks, and to encourage research in the area by highlighting open problems
	and possible directions.

\end{abstract}

%\category{G.2.2}{Discrete Mathematics}{Graph Theory}[Graph algorithms]
%\category{H.2.8}{Database Management}{Database Applications}[Data mining]
%
%\keywords{Centrality, Betweenness, Closeness}

\section*{Intended Audience}
The tutorial is aimed at researchers interested in the theory and the
applications of algorithms for graph mining and social network analysis.

We do not require any specific existing knowledge. The tutorial is designed for
an audience of computer scientists who have a general idea of the problems and
challenges in graph analysis. We plan to present the material in such a way that
any advanced undergraduate student would be able to productively follow our
tutorial.
%and we will actively engage with the audience and adapt our pace and style to ensure
%that every attendee can benefit from our tutorial.

We start from the basic definitions and progressively move to more advanced
algorithms, including sampling-based approximation algorithms and MapReduce
algorithms. Therefore, our tutorial will be of interest both to researchers new
to the field and to a more experienced audience.

\section*{Duration: \textrm{Half-day.}}

\section*{Previous editions of the tutorial}
The tutorial was not previously offered. We did not find any tutorial covering
similar topics in the programs of recent WSDM conferences and of other top
conferences.

\section*{Instructors}
This tutorial is developed by Francesco Bonchi, Gianmarco De Francisci Morales,
and Matteo Riondato. All three instructors will attend the conference.

\para{Francesco Bonchi} is Research Leader at the ISI Foundation, Turin, Italy,
where he leads the "Algorithmic Data Analytics" group. He is also Scientific
Director for Data Mining at Eurecat (Technological Center of Catalunya),
Barcelona. Before he was Director of Research at Yahoo Labs in Barcelona, Spain,
leading the Web Mining Research group.

His recent research interests include mining query-logs, social networks, and
social media, as well as the privacy issues related to mining these kinds of
sensible data.
%In the past he has been interested in data mining query
%languages, constrained pattern mining, mining spatiotemporal and mobility data,
%and privacy preserving data mining.

He will be PC Chair of the 16th IEEE International Conference on Data Mining
(ICDM 2016) to be held in Barcelona in December 2016. He is member of the ECML
PKDD Steering Committee, Associate Editor of the newly created IEEE Transactions
on Big Data (TBD), of the IEEE Transactions on Knowledge and Data Engineering
(TKDE), the ACM Transactions on Intelligent Systems and Technology (TIST),
Knowledge and Information Systems (KAIS), and member of the Editorial Board of
Data Mining and Knowledge Discovery (DMKD).  %
%He has been program co-chair of the
%European Conference on Machine Learning and Principles and Practice of Knowledge
%Discovery in Databases (ECML PKDD 2010). Dr. Bonchi has also served as program
%co-chair of the first and second ACM SIGKDD International Workshop on Privacy,
%Security, and Trust in KDD (PinKDD 2007 and 2008), the 1st IEEE International
%Workshop on Privacy Aspects of Data Mining (PADM 2006), and the 4th
%International Workshop on Knowledge Discovery in Inductive Databases (KDID
%2005).
He is co-editor of the book "Privacy-Aware Knowledge Discovery: Novel
Applications and New Techniques" published by Chapman \& Hall/CRC Press.
%He earned his Ph.D. in computer science from the University of Pisa in December 2003.

He presented a tutorial at ACM KDD'14.


\para{Gianmarco De Francisci Morales} is a Visiting Scientist at Aalto
University. Previously he worked as a Research Scientist at Yahoo Labs
Barcelona, and as a Research Associate at ISTI-CNR in Pisa. His research focuses
on scalable data mining, with an emphasis on Web mining and data-intensive
scalable computing systems.
%He is an active member of the open source community of the Apache Software Foundation, working on the Hadoop ecosystem, and a committer for the Apache Pig project.
He is one of the lead developers of Apache SAMOA, an open-source platform for
mining big data streams. He presented a tutorial on stream mining at IEEE
BigData'14.

\para{Matteo Riondato} is a Research Scientist in the Labs group at Two Sigma
Investments. Previously he was a postdoc at Stanford and at Brown. His
dissertation on sampling-based randomized algorithms for data and graph mining
received the Best Student Poster Award at SIAM SDM'14. His research focuses on
exploiting advanced theory in practical algorithms for time series
analysis, pattern mining, and social network analysis. He presented
tutorials at ACM KDD'15, ECML PKDD'15, and ACM CIKM'15.

\pagebreak
\section*{EXTENDED ABSTRACT}

\subsection*{Motivation}
Identifying the ``important'' nodes or edges in a graph is a fundamental task
in network analysis, with many applications. Many measures, known as
\emph{centrality indices}, have been proposed over the years, formalizing the
concept of importance in different ways~\citep{Newman10}. Centrality measures
rely on graph properties to quantify importance. For example,betweenness
centrality, one of the most commonly used centrality indices, counts the number
of shortest paths going through a node, while the closeness centrality of a node
is the average sum of the inverse of the distance to other nodes. Other
centrality measures use eigenvectors, random walks, degrees, or more complex
properties. The PageRank index of a node is also a centrality measure, and
centrality measures for sets of nodes are also possible.

With the proliferation of huge networks with millions of nodes and billions of
edges, the importance of having scalable algorithms for computing centrality
indices has become more and more evident and a number of contributions have been
recently proposed, ranging from heuristics that perform extremely well in
practice to approximation algorithms offering strong probabilistic guarantees,
to scalable algorithms for the MapReduce platform. Moreover, the dynamic nature
of many networks, i.e., the addition and removal of nodes and/or edges over
time, dictates the need to keep the computed values of centrality up-to-date as
the graph changes. These challenging problems have enjoyed enormous interest
from the research community, with many relevant contributions proposed recently
to tackle them.

Our tutorial presents, in a unified framework, some of the many measures of
centrality and discuss the algorithms to compute them, both in an exact and in
an approximate way, both in-memory and in a parallel/distributed fashion for the
MapReduce framework of computation. This is done with an effort to ease the
comparison between different measures of centrality, the different quality
guarantees offered by approximation algorithms, and the different trade-offs and
scalability behaviors characterizing parallel/distributed algorithms. We believe
this unity of presentation is beneficial both for newcomers and for
experienced researchers in the field, who will be exposes to the material from a
unified point of view.

The graph analyst can now choose among a huge number of centrality indices, from
the well-established ones originally developed in sociology, to the ones more
recently introduced to capture other aspects of ``importance''.  At the same
time, the original algorithms that could handle the relatively small networks
for classic social science experiments have been superseded by important
algorithmic contributions that exploit modern computational frameworks and/or
obtain fast, high-quality approximations. It is our belief that the long history of
centrality measures and the ever-increasing interest from computer
scientists in analyzing larger and richer graphs, create the need for an
all-around organization of both old and new materials, and is the desire to
satisfy this need that inspired us to develop this tutorial.

\subsection*{Outline}
The tutorial is structured in three main technical parts, plus a concluding part
where we discuss future research directions. All the three technical parts will
contains both theory and experimental results.

\begin{enumerate}
	\item {\bf Introduction: definitions and exact algorithms}
		\begin{enumerate}
			\item The axioms of centrality~\citep{BoldiV14}
			\item Definitions of centrality~\citep{Newman10}, including, but not
				limited to: betweenness, closeness, degree, eigenvector,
				harmonic, Katz, absorbing random-walk~\citep{MavroforakisMG15},
				and spanning-edge centrality~\citep{MavroforakisGLKT15}.
			\item Betweenness centrality: exact algorithm~\citep{Brandes01} and
				heuristically-faster exact algorithms for betweenness
				centrality~\citep{ErdosIBT15,SaryuceSKC13}.
			\item Exact algorithms for betweenness centrality in a dynamic
				graph~\citep{LeeLPCC12,NasrePR14,PontecorviR15}.
			\item Exact algorithms for closeness centrality in a dynamic
				graph~\citep{SariyuceKSC13b}.
		\end{enumerate}
	\item {\bf Approximation algorithms}
		\begin{enumerate}
			\item Sampling-based algorithm for closeness
				centrality~\citep{EppsteinW04}.
			\item Betweenness centrality: almost-linear-time approximation
				algorithm~\citep{Yoshida14}, basic sampling-based
				algorithm~\citep{BrandesP07}, refined
				estimators~\citep{GeisbergerSS08}, VC-dimension bounds for
				betweenness centrality~\citep{RiondatoK14WSDM,RiondatoK15}.
			\item Approximation algorithms for betweenness centrality in dynamic
				graphs~\citep{KasWCC13,BergaminiMS14,BergaminiM15}.
		\end{enumerate}
	\item {\bf Highly-scalable algorithms}
		\begin{enumerate}
			\item GPU-based algorithms~\citep{SariyuceKSC13}.
			\item Exact parallel streaming algorithm for betweenness centrality in a
				dynamic graph~\citep{KourtellisMB15}.
		\end{enumerate}
	\item {\bf Challenges and directions for future research}
\end{enumerate}

\subsection*{Links to related resources}
Previous tutorials presented by the instructors:
\begin{description}
	\item Big Data Stream Mining (IEEE BigData'14): \url{https://sites.google.com/site/bigdatastreamminingtutorial}.
	\item VC-Dimension and Rademacher Averages: from Statistical Learning Theory
		to Sampling Algorithms (ACM KDD'15, ECML PKDD'15, ACM CIKM'15) \url{http://bigdata.cs.brown.edu/vctutorial/}.
	\item Correlation Clustering: from Theory to Practice (ACM KDD'14) \url{http://www.francescobonchi.com/CCtuto_kdd14.pdf}.
\end{description}

\subsection*{Support materials}
We are developing a mini-website for the tutorial at
\url{http://matteo.rionda.to/centrtutorial/}. The website will contain the
abstract of the tutorial, a more detailed outline with short a description of
each item of the outline, a full list of references complete with links to
electronic editions, a list of links to software packages implementing the
algorithms we present, and naturally the slides used in the tutorial. A
preliminary version of the website will be available 15 days after the tutorial
is accepted. We plan to work on it and enrich the contents continuously. A
preliminary version of the slides will be available 30 days before the
conference, or in any case by any deadline given to us by the conference
organizers, and the final version will be available 15 days before the
conference.

\bibliographystyle{abbrvnat}
\bibliography{centrtutorial}
\end{document}
